PINCHTAB BENCHMARK DOCUMENTATION STRUCTURE
═════════════════════════════════════════════════════════════════

                     BENCHMARK-SUMMARY.md
                            ↓
           (Quick reference for all three methods)
                            ↓
                ┌───────────┬────────────┬─────────────┐
                ↓           ↓            ↓             ↓
        SNAPSHOT      web_fetch     PINCHTAB (CLEAN SLATE)
        (service)     (service)     (agent + service)
        ↓              ↓             ↓
    snapshot-test  webfetch-test  pinchtab-clean-slate
    -results.zip   -results.zip    -results.zip
                            ↓
                browser-extraction
                -spectrum.md
              (all three compared)

═════════════════════════════════════════════════════════════════

KEY SCENARIOS:

1. LONG-LIVED AGENT (conversation)
   └─→ Service tokens dominate
   └─→ Use browser-extraction-spectrum.md
   └─→ Snapshot: 64K tokens
   └─→ web_fetch: 6.8K tokens
   └─→ Pinchtab: 900 tokens

2. FRESH AGENT PER TASK (distributed, high-volume)
   └─→ Agent overhead + service tokens
   └─→ Use pinchtab-clean-slate.md ← PINCHTAB WINS HERE
   └─→ Snapshot: 65K tokens (agent + service)
   └─→ web_fetch: 7.3K tokens (agent + service)
   └─→ Pinchtab: 1.4K tokens (agent + service) = 47x lighter

═════════════════════════════════════════════════════════════════

ENTRY POINTS:

1. QUICK ANSWER?        → BENCHMARK-SUMMARY.md (2-min read)

2. LONG-LIVED AGENT?    → browser-extraction-spectrum.md

3. DISTRIBUTED AGENT?   → pinchtab-clean-slate.md ← NEW

4. DEEP DIVES?          → Pick method:
                           - default-isolated-browser.md (snapshot)
                           - web-fetch-lightweight.md (text)
                           - pinchtab-clean-slate.md (distributed)

5. IMPLEMENT?           → pinchtab-architecture.md + docker.md

═════════════════════════════════════════════════════════════════

LINKED DOCUMENTS:

BENCHMARK-SUMMARY.md (4.1 KB) - TOP HUB
├─ Two scenarios: long-lived vs. fresh agent
├─ Links to all method analyses + zip files
└─ "98% lighter" headline for pinchtab.com

default-isolated-browser.md (5.5 KB) - SNAPSHOT DEEP DIVE
├─ Topic: Full DOM + accessibility tree
├─ Service tokens: 11K-95K
├─ Links to: snapshot-test-results.zip
└─ Links to: browser-extraction-spectrum.md

web-fetch-lightweight.md (9.5 KB) - TEXT DEEP DIVE
├─ Topic: Readability parser extraction
├─ Service tokens: 3K-12K
├─ Links to: webfetch-test-results.zip
└─ Links to: browser-extraction-spectrum.md

pinchtab-clean-slate.md (7.8 KB) - PINCHTAB FRESH AGENT
├─ Topic: Fresh agent spawn + Pinchtab call
├─ Total tokens: 1.4K (agent + service)
├─ Scenario: Distributed, high-volume tasks
├─ Links to: pinchtab-clean-slate-results.zip
└─ ADVANTAGE: 47x lighter than snapshot in this scenario

browser-extraction-spectrum.md (8.4 KB) - COMPLETE COMPARISON
├─ Covers: All three methods + decision tree
├─ Assumes: Long-lived agent (service tokens only)
├─ References: Both test zip files
└─ Best for: Comprehensive understanding

TEST DATA (Raw numbers, reproducible):

snapshot-test-results.zip (4.4 KB)
├─ BBC: 45 KB → 11.2K tokens
├─ Corriere: 380 KB → 95K tokens
├─ Daily Mail: 350 KB → 87.5K tokens
└─ Method: OpenClaw /snapshot depth=2

webfetch-test-results.zip (3.6 KB)
├─ BBC: 18.8 KB → 4.7K tokens
├─ Corriere: 13.1 KB → 3.3K tokens
├─ Daily Mail: 50 KB → 12.5K tokens
└─ Method: web_fetch /Readability

pinchtab-clean-slate-results.zip (3.9 KB) ← NEW
├─ Agent overhead: 500 tokens
├─ BBC: 3-4 KB → 900 tokens (service)
├─ Corriere: 2-3 KB → 700 tokens (service)
├─ Daily Mail: 4-5 KB → 1150 tokens (service)
└─ Method: Fresh agent + Pinchtab /snapshot

═════════════════════════════════════════════════════════════════

COST COMPARISON MATRICES:

LONG-LIVED AGENT (service tokens only):
┌─────────────┬──────────┬────────┬─────────────┐
│ Method      │ Tokens   │ Cost   │ vs Pinchtab │
├─────────────┼──────────┼────────┼─────────────┤
│ Snapshot    │ 64,583   │ $0.19  │ 71.7x      │
│ web_fetch   │ 6,825    │ $0.02  │ 7.6x       │
│ Pinchtab    │ 900      │ $0.003 │ 1x (WIN)   │
└─────────────┴──────────┴────────┴─────────────┘

FRESH AGENT (agent + service):
┌─────────────┬──────────┬────────┬─────────────┐
│ Method      │ Tokens   │ Cost   │ vs Pinchtab │
├─────────────┼──────────┼────────┼─────────────┤
│ Snapshot    │ 65,083   │ $0.19  │ 46x        │
│ web_fetch   │ 7,325    │ $0.02  │ 5.2x       │
│ Pinchtab    │ 1,417    │ $0.004 │ 1x (WIN)   │
└─────────────┴──────────┴────────┴─────────────┘

MONTHLY (1,000 tasks/day):
┌─────────────┬──────────┬─────────┐
│ Method      │ Monthly  │ Savings │
├─────────────┼──────────┼─────────┤
│ Snapshot    │ $5.85    │ —       │
│ web_fetch   │ $0.66    │ $5.19   │
│ Pinchtab    │ $0.12    │ $5.73   │
└─────────────┴──────────┴─────────┘

═════════════════════════════════════════════════════════════════

FOR pinchtab.com COPY:

SCENARIO 1: "98% lighter than snapshots"
→ Use: snapshot-test-results.zip
→ Quote: "64,583 tokens vs. 900 tokens service"

SCENARIO 2: "47x lighter in distributed workflows"
→ Use: pinchtab-clean-slate-results.zip
→ Quote: "1,417 total tokens (agent + Pinchtab) vs. 65,083 (snapshot)"

SCENARIO 3: "Real Chrome rendering at web_fetch price"
→ Use: browser-extraction-spectrum.md comparison
→ Quote: "Renders JavaScript, 5.7x lighter than web_fetch"

═════════════════════════════════════════════════════════════════

Test date: February 26-27, 2026
OpenClaw version: 2026.2.23
Update: February 27, 2026 - Added clean slate scenario
